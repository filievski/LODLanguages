{
  "name": "tika",
  "version": "1.3.0",
  "description": "Apache Tika bridge. Text extraction, metadata extraction, mimetype detection and language detection.",
  "keywords": [
    "docx",
    "pdf",
    "doc",
    "xlsx",
    "content analysis",
    "office"
  ],
  "homepage": "https://github.com/ICIJ/node-tika",
  "main": "./tika",
  "author": {
    "name": "Matthew Caruana Galizia",
    "email": "mcaruana@icij.org"
  },
  "contributors": [
    {
      "name": "Matthias Götzke",
      "email": "m.goetzke@curasystems.de"
    }
  ],
  "repository": {
    "type": "git",
    "url": "https://github.com/ICIJ/node-tika.git"
  },
  "bugs": {
    "url": "https://github.com/ICIJ/node-tika/issues"
  },
  "license": "MIT",
  "dependencies": {
    "java": "~0.6.0"
  },
  "devDependencies": {
    "mocha": "~2.1.0",
    "istanbul": "~0.3.5"
  },
  "engines": {
    "node": ">=0.10.0"
  },
  "readme": "# node-tika #\n\nProvides text extraction, metadata extraction, mime-type detection, text-encoding detection and language \ndetection. All via a native Java bridge with the Apache Tika content-analysis toolkit. Bundles [Tika \n1.10](http://tika.apache.org/1.10/index.html).\n\n[![Build Status](https://travis-ci.org/ICIJ/node-tika.png?branch=master)](https://travis-ci.org/ICIJ/node-tika) [![npm version](https://badge.fury.io/js/tika.png)](https://badge.fury.io/js/tika)\n\nDepends on [node-java](https://github.com/joeferner/node-java), which itself requires the JDK and Python 2 (not 3) to compile.\n\nRequires JDK 7. Run `node version` to check the version that `node-java` is using. If the wrong version is\nreported even if you installed JDK 1.7, make sure `JAVA_HOME` is set to the correct path then delete `node_modules/java` and rerun `npm install`.\n\n## Extracting text ##\n\n```javascript\nvar tika = require('tika');\n\nvar options = {\n\n\t// Hint the content-type. This is optional but would help Tika choose a parser in some cases.\n\tcontentType: 'application/pdf'\n};\n\ntika.text('test/data/file.pdf', options, function(err, text) {\n\tconsole.log(text);\n});\n```\n\nWe can even extract directly from the Web. If the server returns a content-type header, it will be passed to Tika as a hint.\n\n```javascript\ntika.text('http://www.ohchr.org/EN/UDHR/Documents/UDHR_Translations/eng.pdf', function(err, text) {\n\t// ...\n});\n```\n\nOr extract text using OCR (requires [Tesseract](https://wiki.apache.org/tika/TikaOCR)).\n\n```javascript\ntika.text('test/data/ocr/simple.jpg', {\n\tocrLanguage: 'eng'\n}, function(err, text) {\n\t// ...\n});\n```\n\n## API ##\n\nAll methods that accept a `uri` parameter accept relative or absolute file paths and `http:`, `https:` or `ftp:` URLs.\n\nThe available options are the following.\n\n - `contentType` to provide a hint to Tika on which parser to use.\n - `outputEncoding` to specify the text output encoding. Defaults to UTF-8.\n - `password` to set a password to be used for encrypted files.\n - `maxLength` to specify a max number of character to extract.\n\n### OCR options ###\n\n - `ocrLanguage` to set the language used by Tesseract. This option is required to enable OCR.\n - `ocrPath` to set the path to the Tesseract binaries.\n - `ocrMaxFileSize` to set maximum file size in bytes to submit to OCR.\n - `ocrMinFileSize` to set minimum file size in bytes to submit to OCR.\n - `ocrPageSegmentationMode` to set the Tesseract page segmentation mode.\n - `ocrTimeout` to set the maximum time in seconds to wait for the Tesseract process to terminate.\n\n### PDF parser options ###\n\n - `pdfAverageCharTolerance` see [`PDFTextStripper.setAverageCharTolerance(float)`](http://pdfbox.apache.org/docs/1.8.8/javadocs/org/apache/pdfbox/util/PDFTextStripper.html#setAverageCharTolerance%28float%29).\n - `pdfEnableAutoSpace` to set whether the parser should estimate where spaces should be inserted between words (`true` by default).\n - `pdfExtractAcroFormContent` to set whether content should be extracted from AcroForms at the end of the document (`true` by default).\n - `pdfExtractAnnotationText` to set whether to extract text from annotations (`true` by default).\n - `pdfExtractInlineImages` to set whether to extract inline embedded OBX images.\n - `pdfExtractUniqueInlineImagesOnly` as multiple pages within a PDF file might refer to the same underlying image.\n - `pdfSortByPosition` to set whether to sort text tokens by their x/y position before extracting text.\n - `pdfSpacingTolerance` see [`PDFTextStripper.setSpacingTolerance(float)`](http://pdfbox.apache.org/docs/1.8.8/javadocs/org/apache/pdfbox/util/PDFTextStripper.html#setSpacingTolerance%28float%29).\n - `pdfSuppressDuplicateOverlappingText` to set whether the parse should try to remove duplicated text over the same region.\n - `pdfUseNonSequentialParser` to set whether to use PDFBox's non-sequential parser.\n\n### tika.extract(uri, [options,] cb) ###\n\nExtract both text and metadata from a file.\n\n```javascript\ntika.extract('test/data/file.pdf', function(err, text, meta) {\n\tconsole.log(text); // Logs 'Just some text'.\n\tconsole.log(meta.producer[0]); // Logs 'LibreOffice 4.1'.\n});\n```\n\n### tika.text(uri, [options,] cb) ###\n\nExtract text from a file.\n\n```javascript\ntika.text('test/data/file.pdf', function(err, text) {\n\tconsole.log(text);\n});\n```\n\n### tika.xhtml(uri, [options,] cb) ###\n\nGet an XHTML representation of the text extracted from a file.\n\n```javascript\ntika.xhtml('test/data/file.pdf', function(err, xhtml) {\n\tconsole.log(xhtml);\n});\n```\n\n### tika.meta(uri, [options,] cb) ###\n\nExtract metadata from a file. Returns an object with names as keys and arrays as values.\n\n```javascript\ntika.meta('test/data/file.pdf', function(err, meta) {\n\tconsole.log(meta.producer[0]); // Logs 'LibreOffice 4.1'.\n});\n```\n\n### tika.type(uri, cb) ###\n\nDetect the content-type (MIME type) of a file.\n\n```javascript\ntika.type('test/data/file.pdf', function(err, contentType) {\n\tconsole.log(contentType); // Logs 'application/pdf'.\n});\n```\n\n### tika.charset(uri, [options,] cb) ###\n\nDetect the character set (text encoding) of a file.\n\n```javascript\ntika.charset('test/data/file.txt', function(err, charset) {\n\tconsole.log(charset); // Logs 'ISO-8859-1'.\n});\n```\n\n### tika.typeAndCharset(uri, cb) ###\n\nDetect the content-type and character set of a file.\n\nThe character set will be appended to the mime-type if available.\n\n```javascript\ntika.typeAndCharset('test/data/file.txt', function(err, typeAndCharset) {\n\tconsole.log(typeAndCharset); // Logs 'text/plain; charset=ISO-8859-1'.\n});\n```\n\n### tika.language(string, cb) ###\n\nDetect the language a given string is written in.\n\n```javascript\ntika.language('This is just some text in English.', function(err, language, reasonablyCertain) {\n\tconsole.log(language); // Logs 'en'.\n\tconsole.log(reasonablyCertain); // Logs true or false.\n});\n```\n\n## Credits and collaboration ##\n\nDeveloped by [Matthew Caruana Galizia](https://twitter.com/mcaruanagalizia) at the [ICIJ](http://www.icij.org/).\n\nPlease feel free to submit an issue or pull request. Don't forget to add your name to the `CONTRIBUTORS` file.\n\n## License ##\n\nCopyright (c) 2013 The Center for Public Integrity®. See `LICENSE`.\n\nApache Tika JAR distributed under the [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0).\n",
  "readmeFilename": "README.md",
  "_id": "tika@1.3.0",
  "_from": "tika@"
}
